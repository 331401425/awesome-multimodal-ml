# Reading List for Topics in Multimodal Machine Learning
By [Paul Pu Liang](http://www.cs.cmu.edu/~pliang/) (pliang@cs.cmu.edu), [Machine Learning Department](http://www.ml.cmu.edu/) and [Language Technologies Institute](https://www.lti.cs.cmu.edu/), [CMU](https://www.cmu.edu/). If there are any areas, papers, and datasets I missed, please let me know!

# Research Papers

## Survey Papers

## Core Areas

### Multimodal Fusion

### Multimodal Alignment

### Multimodal Translation

### Co-learning

### Graphs

### Knowledge Bases

### Intepretable Learning

### Transfer Learning

### Semi-supervised Learning

### Self-supervised Learning

### Unsupervised Learning

## Applications

### Language and Visual QA

#### Datasets

#### Papers

### Language Grounding in QA

#### Datasets

#### Papers

### Language Grouding in Navigation

#### Datasets

#### Papers

### Emergence of Language

#### Datasets

#### Papers

### Commonsense Reasoning

#### Datasets

#### Papers

### Multimodal Reinforcement Learning

#### Datasets

#### Papers

### Multimodal Dialog

#### Datasets

#### Papers

### Language and Audio

#### Datasets

#### Papers

### Video-based Activity Recognition

#### Datasets

#### Papers

### Video-based Sentiment and Emotion Recognition

#### Datasets

#### Papers

### Healthcare

#### Datasets

#### Papers

### Self-driving Cars

#### Datasets

#### Papers

### Robotics

#### Datasets

#### Papers

# Workshops

The How2 Challenge: New Tasks for Vision & Language, ICML 2019 https://srvk.github.io/how2-challenge/

Visual Question Answering and Dialog, CVPR 2019 https://visualqa.org/workshop.html

Multi-modal Learning from Videos, CVPR 2019

Multimodal Learning and Applications Workshop, CVPR 2019 https://mula-workshop.github.io/

Habitat: Embodied Agents Challenge and Workshop, CVPR 2019

Closing the Loop Between Vision and Language & LSMD Challenge, ICCV 2019

Multi-modal Video Analysis and Moments in Time Challenge, ICCV 2019

Cross-Modal Learning in Real World, ICCV 2019

Workshop on YouTube-8M Large-Scale Video Understanding, ICCV 2019, ECCV 2018, CVPR 2017 https://research.google.com/youtube8m/workshop2018/

Language and Vision Workshop, CVPR 2019, CVPR 2018, CVPR 2017, CVPR 2015

Sight and Sound, CVPR 2019, CVPR 2018 http://sightsound.org/

Visually Grounded Interaction and Language, NeurIPS 2018 https://nips2018vigil.github.io/

Interpretability and Robustness in Audio, Speech, and Language, NeurIPS 2018 https://irasl.gitlab.io/

Workshop on Shortcomings in Vision and Language, ECCV 2018 https://sites.google.com/view/sivl/

Multimodal Learning and Applications Workshop, ECCV 2018

Grand Challenge and Workshop on Human Multimodal Language, ACL 2018

Workshop on Visual Understanding Across Modalities, CVPR 2017

VQA Challenge Workshop, CVPR 2017

International Workshop on Computer Vision for Audio-Visual Media, ICCV 2017

The Joint Video and Language Understanding Workshop: MovieQA and The Large Scale Movie Description Challenge, ICCV 2017

Workshop on Computational Approaches to Subjectivity, Sentiment and Social Media Analysis: EMNLP 2017, NAACL-HLT 2016, EMNLP 2015, ACL 2014, NAACL-HLT 2013.

Computer Vision for Audio-visual Media, ECCV 2016

Workshop on Language and Vision: ACL 2016, EMNLP 2015

# Tutorials
Connecting Language and Vision to Actions, ACL 2018 https://lvatutorial.github.io/

Multimodal Machine Learning, ACL 2017, CVPR 2016, ICMI 2016

Vision and Language: Bridging Vision and Language with Deep Learning, ICIP 2017

# Courses
CMU 11-777, Advanced Multimodal Machine Learning 

CMU 16-785, Integrated Intelligence in Robotics: Vision, Language, and Planning http://www.cs.cmu.edu/~jeanoh/16-785/

CMU 10-808, Language Grounding to Vision and Control https://katefvision.github.io/LanguageGrounding/

Virginia Tech CS 6501-004, Vision & Language http://www.cs.virginia.edu/~vicente/vislang/
