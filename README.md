# Reading List for Topics in Multimodal Machine Learning
By [Paul Pu Liang](http://www.cs.cmu.edu/~pliang/) (pliang@cs.cmu.edu), [Machine Learning Department](http://www.ml.cmu.edu/) and [Language Technologies Institute](https://www.lti.cs.cmu.edu/), [CMU](https://www.cmu.edu/). If there are any areas, papers, and datasets I missed, please let me know!

# Research Papers

## Survey Papers

## Core Areas

### Multimodal Fusion

### Multimodal Alignment

### Multimodal Translation

### Co-learning

### Graphs

### Knowledge Bases

### Intepretable Learning

### Transfer Learning

### Semi-supervised Learning

### Self-supervised Learning

### Unsupervised Learning

## Applications

### Language and Visual QA

#### Datasets

#### Papers

### Language Grounding in QA

#### Datasets

#### Papers

### Language Grouding in Navigation

#### Datasets

#### Papers

### Emergence of Language

#### Datasets

#### Papers

### Commonsense Reasoning

#### Datasets

#### Papers

### Multimodal Reinforcement Learning

#### Datasets

#### Papers

### Multimodal Dialog

#### Datasets

#### Papers

### Language and Audio

#### Datasets

#### Papers

### Video-based Activity Recognition

#### Datasets

#### Papers

### Video-based Sentiment and Emotion Recognition

#### Datasets

#### Papers

### Healthcare

#### Datasets

#### Papers

### Self-driving Cars

#### Datasets

#### Papers

### Robotics

#### Datasets

#### Papers

# Workshops

The How2 Challenge: New Tasks for Vision & Language, ICML 2019 [link](https://srvk.github.io/how2-challenge/)

Visual Question Answering and Dialog, CVPR 2019, CVPR 2017 [link](https://visualqa.org/workshop.html)

Multi-modal Learning from Videos, CVPR 2019 [link](https://sites.google.com/view/mmlv/home)

Multimodal Learning and Applications Workshop, CVPR 2019, ECCV 2018 [link](https://mula-workshop.github.io/)

Habitat: Embodied Agents Challenge and Workshop, CVPR 2019 [link](https://aihabitat.org/workshop/)

Closing the Loop Between Vision and Language & LSMD Challenge, ICCV 2019 [link](https://sites.google.com/site/iccv19clvllsmdc/)

Multi-modal Video Analysis and Moments in Time Challenge, ICCV 2019 [link](https://sites.google.com/view/multimodalvideo/)

Cross-Modal Learning in Real World, ICCV 2019 [link](https://cromol.github.io/)

Spatial Language Understanding and Grounded Communication for Robotics, NAACL 2019 [link](https://splu-robonlp.github.io/)

YouTube-8M Large-Scale Video Understanding, ICCV 2019, ECCV 2018, CVPR 2017 [link](https://research.google.com/youtube8m/workshop2018/)

Language and Vision Workshop, CVPR 2019, CVPR 2018, CVPR 2017, CVPR 2015 [link](http://languageandvision.com/)

Sight and Sound, CVPR 2019, CVPR 2018 [link](http://sightsound.org/)

The Large Scale Movie Description Challenge (LSMDC), ICCV 2019, ICCV 2017 [link](https://sites.google.com/site/describingmovies/)

Visually Grounded Interaction and Language, NeurIPS 2018 [link](https://nips2018vigil.github.io/)

Wordplay: Reinforcement and Language Learning in Text-based Games, NeurIPS 2018 [link](https://www.wordplay2018.com/)

Interpretability and Robustness in Audio, Speech, and Language, NeurIPS 2018 [link](https://irasl.gitlab.io/)

Shortcomings in Vision and Language, ECCV 2018 [link](https://sites.google.com/view/sivl/)

Grand Challenge and Workshop on Human Multimodal Language, ACL 2018 [link](http://multicomp.cs.cmu.edu/acl2018multimodalchallenge/)

Computational Approaches to Subjectivity, Sentiment and Social Media Analysis: EMNLP 2018, EMNLP 2017, NAACL-HLT 2016, EMNLP 2015, ACL 2014, NAACL-HLT 2013 [link](https://wt-public.emm4u.eu/wassa2018/)

Visual Understanding Across Modalities, CVPR 2017 [link](http://vuchallenge.org/)

International Workshop on Computer Vision for Audio-Visual Media, ICCV 2017 [link](https://cvavm2017.wordpress.com/)

Language Grounding for Robotics, ACL 2017 [link](https://robo-nlp.github.io/2017_index.html)

Computer Vision for Audio-visual Media, ECCV 2016 [link](https://cvavm2016.wordpress.com/)

Language and Vision: ACL 2016, EMNLP 2015 [link](https://vision.cs.hacettepe.edu.tr/vl2016/)

# Tutorials
Connecting Language and Vision to Actions, ACL 2018 [link](https://lvatutorial.github.io/)

Multimodal Machine Learning, ACL 2017, CVPR 2016, ICMI 2016 [link](https://sites.google.com/site/multiml2016cvpr/)

Vision and Language: Bridging Vision and Language with Deep Learning, ICIP 2017 [link](https://www.microsoft.com/en-us/research/publication/vision-language-bridging-vision-language-deep-learning/)

# Courses
CMU 11-777, Advanced Multimodal Machine Learning 

CMU 16-785, Integrated Intelligence in Robotics: Vision, Language, and Planning [link](http://www.cs.cmu.edu/~jeanoh/16-785/)

CMU 10-808, Language Grounding to Vision and Control [link](https://katefvision.github.io/LanguageGrounding/)

Virginia Tech CS 6501-004, Vision & Language [link](http://www.cs.virginia.edu/~vicente/vislang/)
